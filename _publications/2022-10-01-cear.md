---
title: "CEAR: Comprehensive Event Camera Dataset for Rapid Perception of Agile Quadruped Robots"
collection: publications
category: manuscripts
permalink: /publication/2022-10-01-cear
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2024-07-14
venue: 'Robot and Automation Letters (RAL), June 2024'
slidesurl: 'https://kitaharasetusna.github.io/zixun-xiong.github.io/files/Protecting_LLMs_from_Advanced_Thieves.pdf'
paperurl: 'https://arxiv.org/pdf/2404.04698v3'
bibtexurl: 'https://academicpages.github.io/files/bibtex1.bib'
citation: 'Zhu, Shifan, Zixun Xiong, and Donghyun Kim. "Cear: Comprehensive event camera dataset for rapid perception of agile quadruped robots." IEEE Robotics and Automation Letters (2024).'
---
When legged robots perform agile movements, traditional RGB cameras often produce blurred images, posing a challenge for rapid perception. Event cameras have emerged as a promising solution for capturing rapid perception and coping with challenging lighting conditions thanks to their low latency, high temporal resolution, and high dynamic range. However, integrating event cameras into agile-legged robots is still largely unexplored. Notably, no dataset including event cameras has yet been developed for the context of agile quadruped robots. To bridge this gap, we introduce CEAR, a dataset comprising data from an event camera, an RGB-D camera, an IMU, a LiDAR, and joint encoders, all mounted on a dynamic quadruped, Mini Cheetah robot. This comprehensive dataset features more than 100 sequences from real-world environments, encompassing various indoor and outdoor environments, different lighting conditions, a range of robot gaits (e.g., trotting, bounding, pronking), as well as acrobatic movements like backflip. To our knowledge, this is the first event camera dataset capturing the dynamic and diverse quadruped robot motions under various setups, developed to advance research in rapid perception for quadruped robots.
